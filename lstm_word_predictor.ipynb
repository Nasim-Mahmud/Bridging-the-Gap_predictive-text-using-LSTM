{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhQj5C6HZ8ADDKxSXnnWI+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nasim-Mahmud/LSTM-projects/blob/main/lstm_word_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "w1-APtPco5nk",
        "outputId": "521aae16-2682-42b5-c94e-944672421e87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human nature, a concept as old as time itself, has captivated the minds of philosophers, scientists, and ordinary individuals alike. It is a complex and multifaceted enigma, a tapestry woven from threads of biology, psychology, sociology, and culture. Understanding human nature is not merely an academic pursuit; it is a fundamental quest to comprehend the very essence of our existence, the driving forces that shape our behaviors, and the potential that lies dormant within us. From a biological perspective, human nature is deeply rooted in our evolutionary heritage. We are social creatures, driven by an innate need for connection and belonging. Our brains, the most complex organs on Earth, possess remarkable capacities for learning, reasoning, and creativity. We are also emotional beings, capable of experiencing a vast spectrum of feelings, from love and joy to fear and anger. These biological underpinnings provide the foundation upon which human nature is constructed. Psychology delves deeper into the intricate workings of the human mind, exploring the cognitive processes, emotions, and motivations that underlie our actions. We are driven by a desire for survival, security, and self-preservation. We seek out pleasure and avoid pain, and we are constantly striving to achieve our goals and fulfill our aspirations. Our personalities, shaped by our experiences and interactions with the world, manifest in a myriad of unique ways, contributing to the rich diversity of human nature. Sociology examines the societal context in which human nature unfolds. We are shaped by the cultures we inhabit, the norms and values that guide our interactions, and the social structures that define our roles and relationships. Our sense of identity, our perceptions of the world, and our expectations for behavior are all influenced by the social milieu in which we are immersed. Culture, the dynamic expression of human creativity, plays a profound role in shaping our nature. It encompasses our beliefs, values, customs, traditions, and artistic expressions, forming the bedrock of our collective identity. Culture provides us with a sense of belonging, a framework for understanding the world, and a means of expressing our unique experiences and aspirations. The tapestry of human nature is further enriched by the interplay of individual differences and universal traits. While we share certain fundamental characteristics as a species, each individual is a unique blend of experiences, genetics, and personal attributes. This diversity of human nature is a source of both strength and challenge, allowing us to adapt to diverse environments and fostering innovation, but also leading to conflicts and misunderstandings. In conclusion, human nature is a dynamic and multifaceted concept, shaped by a complex interplay of biological, psychological, sociological, and cultural factors. Understanding human nature is an ongoing journey, a continuous process of exploration and self-discovery. As we delve deeper into the mysteries of our minds and the intricacies of our social world, we gain a greater appreciation for the extraordinary complexity and potential that lie at the heart of humanity.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 358
        }
      ],
      "source": [
        "paths = \"/content/test_data.docs\"\n",
        "docs = \"\"\n",
        "with open(paths, 'r') as doc:\n",
        "  docs = doc.read()\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to build a dataset based on the given text, so first we need to convert this strings into integers so that our model can work on it.\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "5T0jTjJtschx"
      },
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "eXZoQwA_t9zN"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning a integer to every number\n",
        "tokenizer.fit_on_texts([docs])\n",
        "# See the tokenized words\n",
        "# tokenizer.word_index"
      ],
      "metadata": {
        "id": "Z6h10ZosuxuQ"
      },
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = []\n",
        "# Separating all the sentences based on line break.\\\n",
        "for sentence in docs.split(\"\\n\"):\n",
        "  # Converting every sentence to a sequence using its designated integer values. Getting a numeric representation.\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  # Converting sequences to a dataset of given input and output\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_seq.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "j3gtDQCQu63D"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_seq"
      ],
      "metadata": {
        "id": "Cmxtqrd4vf_z"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengthOfLargestSeq = max([len(x) for x in input_seq])\n",
        "lengthOfLargestSeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nemesqKg50AZ",
        "outputId": "f508c2a1-cd85-4f1f-cbdf-90db022aff04"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "488"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using zero padding to make every sequence equal in length, Sparse vectorization.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_seq = pad_sequences(input_seq, maxlen = lengthOfLargestSeq, padding= 'pre')\n",
        "padded_input_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qsIwpch9Wlu",
        "outputId": "4eaa68ed-8e1f-4c27-ad5b-0d481d4012d4"
      },
      "execution_count": 365,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   6,   7],\n",
              "       [  0,   0,   0, ...,   6,   7,   5],\n",
              "       [  0,   0,   0, ...,   7,   5,  31],\n",
              "       ...,\n",
              "       [  0,   0,   6, ..., 240,   2, 241],\n",
              "       [  0,   6,   7, ...,   2, 241,   3],\n",
              "       [  6,   7,   5, ..., 241,   3, 242]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_seq[:, :-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJwQRxT8GzQR",
        "outputId": "57b5c784-d21e-43c2-f905-e4a4f96eceff"
      },
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   6],\n",
              "       [  0,   0,   0, ...,   0,   6,   7],\n",
              "       [  0,   0,   0, ...,   6,   7,   5],\n",
              "       ...,\n",
              "       [  0,   0,   6, ..., 239, 240,   2],\n",
              "       [  0,   6,   7, ..., 240,   2, 241],\n",
              "       [  6,   7,   5, ...,   2, 241,   3]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_seq[:, -1]"
      ],
      "metadata": {
        "id": "Em__MQDdHKPj"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLPcxeYjHYUa",
        "outputId": "1406db8d-1d91-4bd5-b11d-74ac3afd8115"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(487, 487)"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaBv-B__IByA",
        "outputId": "8664aa54-8a1a-4cb3-bc72-2899fa8b721d"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(487,)"
            ]
          },
          "metadata": {},
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWords = len(tokenizer.word_index)"
      ],
      "metadata": {
        "id": "Cwm8Otw3I3H-"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using one hot encoding\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes= numOfWords + 1)\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TilMHZPqIZfJ",
        "outputId": "a3acafac-e15f-456c-a1a3-dc2491b10f41"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(487, 243)"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the LSTM architecture**"
      ],
      "metadata": {
        "id": "RTrty41yMQ2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "DNpclvbIMZ2G"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Converting Sparse vectorization to Embedding, shape will be 100, input lenght will be the length of largest sequence -1.\n",
        "model.add(Embedding(numOfWords + 1, 100, input_length= lengthOfLargestSeq - 1))\n",
        "\n",
        "# Number of nodes in the gate of LSTM layer\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(numOfWords + 1, activation= \"softmax\"))"
      ],
      "metadata": {
        "id": "QpPFy2rzM97T"
      },
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "AqHwGCb_OaUB"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY7DVVscOkuX",
        "outputId": "1570f0a7-69dd-40be-ea2b-2d3c5148332e"
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 487, 100)          24300     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 243)               36693     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 211593 (826.54 KB)\n",
            "Trainable params: 211593 (826.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs= 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IfwS0owOsCx",
        "outputId": "bebacb4f-9eab-45de-d6b3-b5911783d399"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 16s 874ms/step - loss: 5.4486 - accuracy: 0.0513\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 14s 865ms/step - loss: 5.0862 - accuracy: 0.0637\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 14s 852ms/step - loss: 4.9308 - accuracy: 0.0370\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 13s 847ms/step - loss: 4.8973 - accuracy: 0.0637\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 14s 859ms/step - loss: 4.8886 - accuracy: 0.0534\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 13s 825ms/step - loss: 4.8632 - accuracy: 0.0657\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 13s 786ms/step - loss: 4.8458 - accuracy: 0.0637\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 13s 769ms/step - loss: 4.8229 - accuracy: 0.0821\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 13s 790ms/step - loss: 4.7753 - accuracy: 0.0821\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 14s 826ms/step - loss: 4.6872 - accuracy: 0.1273\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 14s 847ms/step - loss: 4.5882 - accuracy: 0.1602\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 4.4378 - accuracy: 0.1807\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 4.2635 - accuracy: 0.1910\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 4.0977 - accuracy: 0.2320\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 3.9006 - accuracy: 0.2485\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 14s 851ms/step - loss: 3.7200 - accuracy: 0.2854\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 14s 860ms/step - loss: 3.5366 - accuracy: 0.2875\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 3.3618 - accuracy: 0.3121\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 14s 876ms/step - loss: 3.2052 - accuracy: 0.3265\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 14s 866ms/step - loss: 3.0151 - accuracy: 0.3450\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 2.8510 - accuracy: 0.3614\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 14s 864ms/step - loss: 2.6771 - accuracy: 0.3860\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 2.5277 - accuracy: 0.4168\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 14s 865ms/step - loss: 2.3639 - accuracy: 0.4517\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 14s 861ms/step - loss: 2.2211 - accuracy: 0.4990\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 14s 860ms/step - loss: 2.0733 - accuracy: 0.5462\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 1.9328 - accuracy: 0.5852\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 14s 865ms/step - loss: 1.7950 - accuracy: 0.6099\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 13s 828ms/step - loss: 1.6774 - accuracy: 0.6735\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 13s 787ms/step - loss: 1.5550 - accuracy: 0.7043\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 13s 772ms/step - loss: 1.4444 - accuracy: 0.7741\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 13s 791ms/step - loss: 1.3329 - accuracy: 0.8172\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 14s 818ms/step - loss: 1.2383 - accuracy: 0.8296\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 14s 833ms/step - loss: 1.1374 - accuracy: 0.8850\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 1.0541 - accuracy: 0.8994\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 14s 872ms/step - loss: 0.9813 - accuracy: 0.9035\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 14s 869ms/step - loss: 0.9116 - accuracy: 0.9363\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 14s 859ms/step - loss: 0.8518 - accuracy: 0.9446\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.7839 - accuracy: 0.9610\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.7337 - accuracy: 0.9630\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 14s 865ms/step - loss: 0.6789 - accuracy: 0.9671\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 14s 859ms/step - loss: 0.6391 - accuracy: 0.9733\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 14s 861ms/step - loss: 0.5966 - accuracy: 0.9836\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 14s 856ms/step - loss: 0.5538 - accuracy: 0.9877\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.5179 - accuracy: 0.9877\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 14s 862ms/step - loss: 0.4798 - accuracy: 0.9897\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 14s 861ms/step - loss: 0.4512 - accuracy: 0.9918\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 14s 861ms/step - loss: 0.4252 - accuracy: 0.9897\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.3973 - accuracy: 0.9959\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 14s 867ms/step - loss: 0.3774 - accuracy: 0.9979\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 13s 834ms/step - loss: 0.3517 - accuracy: 0.9979\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 13s 777ms/step - loss: 0.3336 - accuracy: 0.9938\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 13s 747ms/step - loss: 0.3186 - accuracy: 0.9979\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 13s 808ms/step - loss: 0.2990 - accuracy: 0.9979\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 14s 844ms/step - loss: 0.2797 - accuracy: 0.9979\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 14s 861ms/step - loss: 0.2654 - accuracy: 0.9979\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 14s 859ms/step - loss: 0.2523 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.2384 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 14s 866ms/step - loss: 0.2285 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 14s 862ms/step - loss: 0.2174 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.2076 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.1964 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 0.1884 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 14s 862ms/step - loss: 0.1793 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 14s 860ms/step - loss: 0.1705 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.1629 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 14s 855ms/step - loss: 0.1571 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.1515 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 14s 855ms/step - loss: 0.1440 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.1384 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 14s 853ms/step - loss: 0.1326 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 13s 798ms/step - loss: 0.1271 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 13s 773ms/step - loss: 0.1229 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 13s 786ms/step - loss: 0.1179 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 13s 799ms/step - loss: 0.1141 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 14s 841ms/step - loss: 0.1097 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 14s 862ms/step - loss: 0.1071 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 14s 862ms/step - loss: 0.1038 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 14s 860ms/step - loss: 0.0991 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.0958 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 14s 855ms/step - loss: 0.0923 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 14s 860ms/step - loss: 0.0895 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.0868 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 14s 866ms/step - loss: 0.0837 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 14s 858ms/step - loss: 0.0813 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 14s 861ms/step - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 14s 857ms/step - loss: 0.0763 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 14s 862ms/step - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 14s 863ms/step - loss: 0.0718 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 14s 859ms/step - loss: 0.0693 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 14s 848ms/step - loss: 0.0677 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 14s 854ms/step - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 13s 848ms/step - loss: 0.0641 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 13s 801ms/step - loss: 0.0623 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 13s 775ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 13s 785ms/step - loss: 0.0587 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 14s 809ms/step - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 14s 840ms/step - loss: 0.0560 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 14s 864ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 14s 859ms/step - loss: 0.0530 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x784bcdfabb80>"
            ]
          },
          "metadata": {},
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "wUVwqThUbKoa"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_predictor(numOfWordsToGenerate, text):\n",
        "  for i in range(numOfWordsToGenerate):\n",
        "    #tokenier\n",
        "    tokenized_text = tokenizer.texts_to_sequences([text])[0]\n",
        "    #padding\n",
        "    padded_text = pad_sequences([tokenized_text], maxlen= lengthOfLargestSeq - 1, padding= \"pre\")\n",
        "    #predict\n",
        "    position = np.argmax(model.predict(padded_text, verbose=0))\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == position:\n",
        "        text = text + \" \" + word\n",
        "  print(text)"
      ],
      "metadata": {
        "id": "S0RPDGsyYmdY"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_words_to_generate = 20\n",
        "given_words = \"What is the\"\n",
        "word_predictor(num_of_words_to_generate, given_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju5nKzZhfw34",
        "outputId": "091009a6-4e67-4b0f-ffd7-dea21d63bc85"
      },
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the nature a concept as old as time itself has captivated the minds of philosophers scientists and ordinary individuals alike it\n"
          ]
        }
      ]
    }
  ]
}